#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Written as part of https://www.scrapehero.com/how-to-scrape-amazon-product-reviews-using-python/
from lxml import html
from json import dump, loads
from requests import get
import json
from re import sub
from dateutil import parser as dateparser
from time import sleep

("\n"
 "\n"
 "def ParseReviews(asin):\n"
 "\n"
 "\n"
 "# This script has only been tested with Amazon.com\n"
 "amazon_url = ‘http: // www.amazon.com / dp / '+asin\n"
 "# Add some recent user agent to prevent amazon from blocking the request\n"
 "# Find some chrome user agent strings here https://udger.com/resources/ua-list/browser-detail?browser=Chrome\n"
 "headers = {‘User - Agent’: ‘Mozilla / 5.0(X11;\n"
 "Linux\n"
 "x86_64) AppleWebKit / 537.36(KHTML, like\n"
 "Gecko) Chrome / 62.0\n"
 ".3202\n"
 ".94\n"
 "Safari / 537.36’}\n"
 "for i in range(5):\n"
 "    response = get(amazon_url, headers=headers, verify=False, timeout=30)\n"
 "if response.status_code == 404:\n"
 "    return {“url”: amazon_url, “error”: “page\n"
 "    not found”}\n"
 "    if response.status_code != 200:\n"
 "        continue\n"
 "\n"
 "    # Removing the null bytes from the response.\n"
 "    cleaned_response = response.text.replace(‘\x00’, ‘’)\n"
 "\n"
 "    parser = html.fromstring(cleaned_response)\n"
 "    XPATH_AGGREGATE = ‘ // span[ @ id =”acrCustomerReviewText”]’\n"
 "    XPATH_REVIEW_SECTION_1 = ‘ // div[contains( @ id,”reviews - summary”)]’\n"
 "    XPATH_REVIEW_SECTION_2 = ‘ // div[ @ data - hook =”review”]’\n"
 "    XPATH_AGGREGATE_RATING = ‘ // table[ @ id =”histogramTable”] // tr’\n"
 "    XPATH_PRODUCT_NAME = ‘ // h1 // span[ @ id =”productTitle”] // text()’\n"
 "    XPATH_PRODUCT_PRICE = ‘ // span[ @ id =”priceblock_ourprice”] / text()’\n"
 "\n"
 "    raw_product_price = parser.xpath(XPATH_PRODUCT_PRICE)\n"
 "    raw_product_name = parser.xpath(XPATH_PRODUCT_NAME)\n"
 "    total_ratings = parser.xpath(XPATH_AGGREGATE_RATING)\n"
 "    reviews = parser.xpath(XPATH_REVIEW_SECTION_1)\n"
 "\n"
 "    product_price = ‘’.join(raw_product_price).replace(‘, ’, ‘’)\n"
 "    product_name = ‘’.join(raw_product_name).strip()\n"
 "\n"
 "    if not reviews:\n"
 "        reviews = parser.xpath(XPATH_REVIEW_SECTION_2)\n"
 "    ratings_dict = {}\n"
 "    reviews_list = []\n"
 "\n"
 "    # Grabing the rating section in product page\n"
 "    for ratings in total_ratings:\n"
 "        extracted_rating = ratings.xpath(‘./ td // a // text()’)\n"
 "        if extracted_rating:\n"
 "            rating_key = extracted_rating[0]\n"
 "        raw_raing_value = extracted_rating[1]\n"
 "        rating_value = raw_raing_value\n"
 "        if rating_key:\n"
 "            ratings_dict.update({rating_key: rating_value})\n"
 "\n"
 "        # Parsing individual reviews\n"
 "        for review in reviews:\n"
 "            XPATH_RATING = ‘.// i[ @ data - hook =”review - star - rating”] // text()’\n"
 "            XPATH_REVIEW_HEADER = ‘.// a[ @ data - hook =”review - title”] // text()’\n"
 "            XPATH_REVIEW_POSTED_DATE = ‘.// span[ @ data - hook =”review - date”] // text()’\n"
 "            XPATH_REVIEW_TEXT_1 = ‘.// div[ @ data - hook =”review - collapsed”] // text()’\n"
 "            XPATH_REVIEW_TEXT_2 = ‘.// div // span[ @ data - action =”columnbalancing - showfullreview”] /\n"
 "\n"
 "            @data - columnbalancing - showfullreview\n"
 "\n"
 "            ’\n"
 "            XPATH_REVIEW_COMMENTS = ‘.// span[ @ data - hook =”review - comment”] // text()’\n"
 "            XPATH_AUTHOR = ‘.// span[contains( @\n"
 "\n"
 "\n"
 "            class ,”profile-name”)] // text()’\n"
 "            XPATH_REVIEW_TEXT_3 = ‘.// div[contains( @ id, ”dpReviews”)] / div / text()’\n"
 "\n"
 "            raw_review_author = review.xpath(XPATH_AUTHOR)\n"
 "            raw_review_rating = review.xpath(XPATH_RATING)\n"
 "            raw_review_header = review.xpath(XPATH_REVIEW_HEADER)\n"
 "            raw_review_posted_date = review.xpath(XPATH_REVIEW_POSTED_DATE)\n"
 "            raw_review_text1 = review.xpath(XPATH_REVIEW_TEXT_1)\n"
 "            raw_review_text2 = review.xpath(XPATH_REVIEW_TEXT_2)\n"
 "            raw_review_text3 = review.xpath(XPATH_REVIEW_TEXT_3)\n"
 "\n"
 "            # Cleaning data\n"
 "            author = ‘ ‘.join(‘ ‘.join(raw_review_author).split())\n"
 "            review_rating = ‘’.join(raw_review_rating).replace(‘out of 5 stars’, ‘’)\n"
 "            review_header = ‘ ‘.join(‘ ‘.join(raw_review_header).split())\n"
 "\n"
 "\n"
 "            try:\n"
 "                review_posted_date = dateparser.parse(‘’.join(raw_review_posted_date)).strftime(‘ % d % b % Y’)\n"
 "                except:\n"
 "                review_posted_date = None\n"
 "                review_text = ‘ ‘.join(‘ ‘.join(raw_review_text1).split())\n"
 "\n"
 "                # Grabbing hidden comments if present\n"
 "                if raw_review_text2:\n"
 "                    json_loaded_review_data = loads(raw_review_text2[0])\n"
 "                json_loaded_review_data_text = json_loaded_review_data[‘rest’]\n"
 "                cleaned_json_loaded_review_data_text = re.sub(‘ <.* ? > ’, ‘’, json_loaded_review_data_text)\n"
 "                full_review_text = review_text + cleaned_json_loaded_review_data_text\n"
 "                else:\n"
 "                full_review_text = review_text\n"
 "                if not raw_review_text1:\n"
 "                    full_review_text = ‘ ‘.join(‘ ‘.join(raw_review_text3).split())\n"
 "\n"
 "                    raw_review_comments = review.xpath(XPATH_REVIEW_COMMENTS)\n"
 "                    review_comments = ‘’.join(raw_review_comments)\n"
 "                    review_comments = sub(‘[A - Za - z]’, ‘’, review_comments).strip()\n"
 "                    review_dict = {\n"
 "                    ‘review_comment_count’: review_comments,\n"
 "                    ‘review_text’: full_review_text,\n"
 "                    ‘review_posted_date’: review_posted_date,\n"
 "                    ‘review_header’: review_header,\n"
 "                    ‘review_rating’: review_rating,\n"
 "                    ‘review_author’: author\n"
 "\n"
 "                    }\n"
 "                    reviews_list.append(review_dict)\n"
 "\n"
 "                    data = {\n"
 "                    ‘ratings’: ratings_dict,\n"
 "                    ‘reviews’: reviews_list,\n"
 "                    ‘url’: amazon_url,\n"
 "                    ‘name’: product_name,\n"
 "                    ‘price’: product_price\n"
 "\n"
 "                    }\n"
 "                    return data\n"
 "\n"
 "                    return {“error”: “failed\n"
 "                    to\n"
 "                    process\n"
 "                    the\n"
 "                    page”, “url”: amazon_url}\n"
 "\n"
 "                    def ReadAsin():\n"
 "\n"
 "\n"
 "                    # Add your own ASINs here\n"
 "                    AsinList = [‘B01ETPUQ6E’, ‘B017HW9DEW’, ‘B00U8KSIOM’]\n"
 "                    extracted_data = []\n"
 "\n"
 "                    for asin in AsinList:\n"
 "                        print(“Downloading and processing\n"
 "                        page\n"
 "                        http: // www.amazon.com / dp / \" + asin)\n"
 "                        extracted_data.append(ParseReviews(asin))\n"
 "                        sleep(5)\n"
 "                        f = open(‘data.json’, ‘w’)\n"
 "                        dump(extracted_data, f, indent=4)\n"
 "                        f.close()\n"
 "\n"
 "                        if __name__ == ‘__main__’:\n"
 "                        ReadAsin()\n")